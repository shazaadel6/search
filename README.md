!pip install gradio langdetect sentence-transformers torch SpeechRecognition pydub -q
import gradio as gr
from langdetect import detect, LangDetectException
from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd
import speech_recognition as sr
import io
from pydub import AudioSegment

model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')

students_data = pd.DataFrame([
    {"name": "Ø£Ø­Ù…Ø¯ Ø¹Ù„ÙŠ", "national_id": "1234567890", "grade": "Ø§Ù„Ø«Ø§Ù„Ø« Ø§Ù„Ø«Ø§Ù†ÙˆÙŠ", "disease": "Ø§Ù„Ø³ÙƒØ±"},
    {"name": "Ù…Ø­Ù…Ø¯ Ø­Ø³Ù†", "national_id": "9876543210", "grade": "Ø§Ù„Ø«Ø§Ù†ÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ÙŠ", "disease": "Ø§Ù„Ø¶ØºØ·"},
    {"name": "Sara Ahmed", "national_id": "5555555555", "grade": "Grade 10", "disease": "Diabetes"},
    {"name": "Ali Hassan", "national_id": "1111222233", "grade": "Grade 12", "disease": "None"},
    {"name": "Ù…Ø±ÙŠÙ… ÙŠÙˆØ³Ù", "national_id": "9999999999", "grade": "Ø§Ù„Ø£ÙˆÙ„ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠ", "disease": "None"},
])

def smart_search(query):
    try:
        lang = detect(query)
    except LangDetectException:
        lang = "en"
    query_emb = model.encode([query], convert_to_numpy=True)
    student_texts = students_data.apply(lambda row: f"{row['name']} {row['national_id']} {row['grade']} {row['disease']}", axis=1)
    text_embs = model.encode(student_texts.tolist(), convert_to_numpy=True)
    cosine_scores = np.dot(query_emb, text_embs.T) / (np.linalg.norm(query_emb) * np.linalg.norm(text_embs, axis=1))
    top_idx = np.argmax(cosine_scores)
    if cosine_scores[0][top_idx] < 0.4:
        return "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù‚Ø±ÙŠØ¨Ø©. Ø¬Ø±Ù‘Ø¨ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø®ØªÙ„ÙØ©."
    result = students_data.iloc[top_idx]
    return f"ğŸ‘¤ Ø§Ù„Ø§Ø³Ù…: {result['name']}\nğŸ†” Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù‚ÙˆÙ…ÙŠ: {result['national_id']}\nğŸ« Ø§Ù„ØµÙ: {result['grade']}\nğŸ’Š Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ØµØ­ÙŠØ©: {result['disease']}"

def speech_to_text(audio):
    if audio is None:
        return "Ù„Ù… ÙŠØªÙ… Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØª."
    recognizer = sr.Recognizer()
    audio = AudioSegment.from_file(io.BytesIO(audio), format="wav")
    audio.export("temp.wav", format="wav")
    with sr.AudioFile("temp.wav") as source:
        recorded_audio = recognizer.record(source)
    try:
        text = recognizer.recognize_google(recorded_audio, language="ar-AR")
        return text
    except sr.UnknownValueError:
        return "Ù„Ù… Ø£Ø³ØªØ·Ø¹ ÙÙ‡Ù… Ø§Ù„ØµÙˆØªØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

with gr.Blocks(title="ğŸ“š Student Search Assistant") as demo:
    gr.Markdown("## ğŸ“ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø·Ù„Ø§Ø¨ (Ø¹Ø±Ø¨ÙŠ + Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ)")
    with gr.Tab("ğŸ” Ø¨Ø­Ø« Ù†ØµÙŠ"):
        query = gr.Textbox(label="Ø§ÙƒØªØ¨ Ø§Ø³Ù… Ø§Ù„Ø·Ø§Ù„Ø¨ Ø£Ùˆ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ù‚ÙˆÙ…ÙŠ Ø£Ùˆ Ø§Ù„Ù…Ø±Ø¶")
        text_output = gr.Textbox(label="Ø§Ù„Ù†ØªÙŠØ¬Ø©")
        text_button = gr.Button("Ø§Ø¨Ø­Ø«")
        text_button.click(fn=smart_search, inputs=query, outputs=text_output)
    with gr.Tab("ğŸ¤ Ø¨Ø­Ø« ØµÙˆØªÙŠ"):
        audio_input = gr.Audio(sources=["microphone"], type="filepath", label="Ø³Ø¬Ù‘Ù„ ØµÙˆØªÙƒ Ù‡Ù†Ø§")
        audio_text = gr.Textbox(label="Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØµÙˆØª")
        convert_button = gr.Button("ğŸ§ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ")
        convert_button.click(fn=speech_to_text, inputs=audio_input, outputs=audio_text)
        result_button = gr.Button("ğŸ” Ø§Ø¨Ø­Ø« Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª")
        result_button.click(fn=smart_search, inputs=audio_text, outputs=text_output)
demo.launch()
